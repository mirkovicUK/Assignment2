{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def txt_to_pd(path):\n",
    "    \"\"\"takes path to data.txt returns pandas dataframe\"\"\"\n",
    "    raw = open(path).readlines() \n",
    "    raw = [map(float, each.strip().split()) for each in raw] \n",
    "    df_data = list()\n",
    "    for i in range(len(raw)):\n",
    "        df_data.append(list(raw[i]))\n",
    "    df1 = pd.DataFrame(df_data)\n",
    "    return df1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Net Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, input_size, output_size, hidden_layers:list, drop_p=0.2) -> None:\n",
    "        ''' Builds a feedforward network with arbitrary hidden layers.\n",
    "        \n",
    "            Arguments\n",
    "            ---------\n",
    "            input_size: integer, size of the input layer\n",
    "            output_size: integer, size of the output layer\n",
    "            hidden_layers: list of integers, the sizes of the hidden layers\n",
    "        '''\n",
    "        super().__init__()\n",
    "        # add input to hidden \n",
    "        self.layers = nn.ModuleList([nn.Linear(input_size, hidden_layers[0]).float()])\n",
    "        #add hidden layers \n",
    "        layer_sizes = zip(hidden_layers[:-1], hidden_layers[1:])\n",
    "        self.layers.extend([nn.Linear(n1,n2) for n1,n2 in layer_sizes])\n",
    "        #add output layer\n",
    "        self.output = nn.Linear(hidden_layers[-1], output_size)\n",
    "        #dropout\n",
    "        self.dropout = nn.Dropout(p=drop_p)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        #flatten images\n",
    "        x = x.view(x.shape[0], -1)\n",
    "        \n",
    "        #NN\n",
    "        for layer in self.layers:\n",
    "            x =  self.dropout(F.relu(layer(x)))\n",
    "        return F.log_softmax(self.output(x), dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "def train(model, optimizer, criterion, train_loader, valid_loader, min_val_loss = np.Inf,  epochs=5):\n",
    "    \"\"\"\n",
    "        Train model using train_loader data and validate on valid_loaders\n",
    "        returns list of running and validation lost for each epoch \n",
    "        saves best configuration into model.pt\n",
    "\n",
    "        after training call :\n",
    "        model.load_state_dict(torch.load('model.pt')) to avoid overfitting  \n",
    "\n",
    "        if used for transfer learning stuck data across dim =1 (RGB images)\n",
    "    \"\"\"\n",
    "    train_plot, val_plot = [], []\n",
    "    for epoch in range(epochs):\n",
    "        train_loss, val_loss = 0,0\n",
    "\n",
    "        #training loop\n",
    "        model.train() \n",
    "        for data, target in train_loader:\n",
    "            # resnet arhitecture expect data tensor acros 3 channels [3,150,150]\n",
    "            # uncoment for approach 2\n",
    "            #data = torch.stack([data,data,data], dim=1)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)# forward pass\n",
    "            target.squeeze_()\n",
    "            loss = criterion(output, target)#calculate loss\n",
    "            loss.backward() #calculate gradients \n",
    "            optimizer.step() # upddate weights\n",
    "\n",
    "            train_loss+=loss.item() # record running loss\n",
    "\n",
    "        # validation loop \n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for data, target in valid_loader:\n",
    "                # uncoment for approach 2 resnet18 arhitecture\n",
    "                #data = torch.stack([data,data,data], dim=1)\n",
    "                \n",
    "                target.squeeze_()\n",
    "                loss = criterion(model(data), target)\n",
    "                val_loss += loss.item()\n",
    "\n",
    "        # average loss\n",
    "        train_loss = train_loss/ len(train_loader)\n",
    "        val_loss   = val_loss/ len(valid_loader)\n",
    "        print('Epoch:{} \\tTraining_Loss:{:.6}\\tValidation_Loss:{:.6}'.format(epoch+1,train_loss,val_loss))\n",
    "        \n",
    "        # save  average loss across epochs\n",
    "        train_plot.append(train_loss)\n",
    "        val_plot.append(val_loss)\n",
    "        \n",
    "        # save model if validation loss has decreased\n",
    "        if val_loss <= min_val_loss:\n",
    "            print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(\n",
    "            min_val_loss,\n",
    "            val_loss))\n",
    "            print()\n",
    "            torch.save(model.state_dict(), 'model.pt') \n",
    "            min_val_loss = val_loss\n",
    "    \n",
    "    return train_plot, val_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "\n",
    "def test(model, test_loader, criterion, classes:list):\n",
    "    \n",
    "    test_loss = 0.0\n",
    "    class_correct = list(0. for i in range(len(classes))) \n",
    "    class_total = list(0. for i in range(len(classes)))\n",
    "    accuracy = 0\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            #data = torch.stack([data,data,data], dim=1)\n",
    "            \n",
    "            output = model(data)\n",
    "            target.squeeze_()\n",
    "            test_loss += criterion(output, target).item()\n",
    "            probs = torch.exp(output)# get probabilities from model output output\n",
    "            _,idx = torch.topk(probs, k=1, dim=1) # index of element with highest probability\n",
    "            correct = idx == target.view(*idx.shape)\n",
    "            \n",
    "            accuracy += torch.mean(correct.type(torch.FloatTensor))\n",
    "            \n",
    "            # calculate test accuracy for each object class\n",
    "            for i in range(target.size(0)):\n",
    "                label = target[i]\n",
    "                class_correct[label] += correct[i].item()\n",
    "                class_total[label] += 1\n",
    "\n",
    "        # calculate and print avg test loss\n",
    "        test_loss = test_loss/len(test_loader)\n",
    "        print('Test Loss: {:.4f}\\t'.format(test_loss), end=\"\")    \n",
    "        print('\\nTest Accuracy (Overall): {:.4f}'.format(accuracy.item()/len(test_loader)))\n",
    "    \n",
    "    return test_loss, accuracy, class_correct, class_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_test_data(class_correct:list, class_total:list, classes:list):\n",
    "    \"\"\"\n",
    "        class_correct:list -> returned by test function\n",
    "        class_total:list -> returned by test function\n",
    "        classes:list -> what are we classifying\n",
    "    \"\"\"\n",
    "    for i in range(len(classes)):\n",
    "        if class_total[i] > 0:\n",
    "            print('Test Accuracy of %5s: %2d%% (%2d/%2d)' % (\n",
    "            str(classes[i]), 100 * class_correct[i] / class_total[i],\n",
    "            np.sum(class_correct[i]), np.sum(class_total[i])))\n",
    "        else:\n",
    "            print('Test Accuracy of class %5s: N/A (no training examples)' % (i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "fb083f6ed9e3c6a6364dcaf3ceb9deb53bd9123b770e36b77ab89d87b129417d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
